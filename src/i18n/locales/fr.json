{
  "header": {
    "title": "Gemini Nano Playground",
    "subtitle": "Testez l'API Prompt directement dans votre navigateur."
  },
  "controls": {
    "title": "Panneau de Contrôle",
    "subtitle": "Paramètres du Modèle",
    "modelInfo": {
      "title": "Informations du Modèle",
      "subtitle": "Statistiques et détails du modèle",
      "maxTemperature": "Température Maximale",
      "maxTopK": "Top-K Maximum",
      "defaultTemperature": "Température par Défaut",
      "defaultTopK": "Top-K par Défaut"
    },
    "status": {
      "ready": "Prêt",
      "downloading": "Téléchargement",
      "initializing": "Initialisation",
      "error": "Erreur",
      "unverified": "Vérification"
    },
    "temperature": {
      "label": "Température",
      "description": "Contrôle la créativité des réponses. Des valeurs plus élevées génèrent des réponses plus créatives et imprévisibles."
    },
    "topK": {
      "label": "Top-K",
      "description": "Limite le nombre de tokens considérés. Des valeurs plus faibles génèrent des réponses plus ciblées."
    },
    "buttons": {
      "start": "Initialiser Modèle",
      "restart": "Redémarrer Modèle",
      "startSubtitle": "Initialiser le modèle",
      "restartSubtitle": "Redémarrer le modèle"
    },
    "download": {
      "title": "Téléchargement du Modèle",
      "progress": "{{progress}}% terminé",
      "downloading": "Téléchargement du modèle...",
      "subtitle": "Téléchargement des fichiers nécessaires"
    }
  },
  "status": {
    "idle": "En attente d'initialisation",
    "initializing": "Initialisation...",
    "downloading": "Téléchargement du modèle. Cela peut prendre quelques minutes.",
    "ready": "Prêt à utiliser",
    "initialMessage": "Cliquez sur \"Démarrer\" pour vérifier la disponibilité du modèle.",
    "checkingAvailability": "Vérification de la disponibilité du modèle...",
    "modelUnavailable": "Modèle non disponible. Vérifiez les exigences matérielles et système.",
    "creatingSession": "Modèle disponible. Création de session...",
    "downloadProgress": "Téléchargement du modèle : {{progress}}%",
    "sessionReady": "Session prête avec Température={{temperature}} et Top-K={{topK}}.",
    "unknownError": "Erreur inconnue",
    "error": "Erreur : {{message}}",
    "apiNotFound": "API LanguageModel non trouvée. Assurez-vous d'être dans Chrome avec les flags correctes."
  },
  "app": {
    "setupTitle": "Configurer Gemini Nano",
    "downloadingTitle": "Téléchargement du modèle...",
    "initializingTitle": "Initialisation...",
    "setupDescription": "Cliquez sur \"Démarrer\" dans le panneau latéral pour commencer.",
    "downloadingDescription": "Le modèle est en cours de téléchargement en arrière-plan.",
    "initializingDescription": "Préparation de l'IA pour utilisation.",
    "footer": {
      "showGuideLink": "[fr] Show Gemini Nano Guide",
      "hideGuideLink": "[fr] Hide Gemini Nano Guide"
    }
  },
  "prompt": {
    "placeholder": "Tapez votre question ou prompt ici...",
    "send": "Envoyer",
    "stop": "Arrêter",
    "generating": "Génération de la réponse...",
    "empty": "La réponse apparaîtra ici...",
    "label": "Tapez votre question ou prompt :",
    "characterCount": "caractères",
    "startPrompt": "Tapez votre question ci-dessus pour commencer",
    "suggestions": {
      "title": "Suggestions de prompts :",
      "examples": [
        "Expliquez comment fonctionne l'intelligence artificielle",
        "Créez une fonction JavaScript pour trier les tableaux",
        "Quelles sont les meilleures pratiques React ?",
        "Comment optimiser les performances web ?"
      ]
    }
  },
  "output": {
    "error": "Erreur : {{message}}",
    "interrupted": "Génération interrompue"
  },
  "errors": {
    "modelParamsLoad": "Impossible de charger les paramètres du modèle :",
    "apiAvailabilityCheck": "Erreur lors de la vérification de disponibilité de l'API :"
  },
  "setupModal": {
    "title": "Configuration Gemini Nano",
    "copyToClipboard": "Copier dans le presse-papiers",
    "closeModalLabel": "Fermer la modale",
    "alert": {
      "title": "API Gemini Nano Non Disponible",
      "description": "Il semble que l'API Gemini Nano ne soit pas disponible dans votre navigateur. Cela peut être dû au fait que vous n'utilisez pas Chrome Canary/Dev, que les flags expérimentaux ne sont pas activés, ou que votre système ne répond pas aux exigences."
    },
    "introduction": {
      "title": "Qu'est-ce que Gemini Nano ?",
      "description": "Gemini Nano est le modèle d'IA sur l'appareil de Google qui s'exécute localement dans Chrome. Il permet des fonctionnalités d'IA puissantes sans envoyer de données à des serveurs externes, garantissant confidentialité et réponses rapides."
    },
    "requirements": {
      "title": "Configuration Système Requise",
      "osLabel": "Système d'exploitation :",
      "osValue": "Windows 10/11, macOS 13+, ou Linux",
      "storageLabel": "Stockage :",
      "storageValue": "Au moins 22 Go disponibles",
      "gpuLabel": "GPU :",
      "gpuValue": "Plus de 4 Go de VRAM (ou utilisez le contournement CPU - voir ci-dessous)",
      "networkLabel": "Réseau :",
      "networkValue": "Connexion illimitée (pour le téléchargement)"
    },
    "steps": {
      "step1": {
        "title": "Obtenez Chrome Canary ou Dev Channel",
        "description": "Gemini Nano n'est disponible que dans les versions expérimentales de Chrome :",
        "downloadCanary": "Télécharger Chrome Canary",
        "downloadDev": "Télécharger Chrome Dev"
      },
      "step2": {
        "title": "Activer les Flags Expérimentaux",
        "chromeFlags": "Ouvrez Chrome et naviguez vers la page des flags :",
        "enableApi": "Activez l'API Gemini Nano :",
        "setFlagToEnabled": "Passez de \"Par défaut\" à \"Activé\"",
        "restart": "Redémarrez Chrome :",
        "relaunchDescription": "Cliquez sur le bouton \"Relancer\" qui apparaît en bas de la page."
      },
      "step3": {
        "title": "Traitement par CPU (Optionnel)",
        "description": "Vous n'avez pas de GPU dédiée avec 4+ GB VRAM ? Activez le traitement par CPU avec ce flag supplémentaire :",
        "searchFlag": "Recherchez ce flag et définissez-le sur \"Enabled\"",
        "ignoreGpu": "Ceci ignore les exigences GPU et utilise le CPU",
        "performance": "Les performances peuvent être plus lentes, mais toujours fonctionnelles"
      },
      "step4": {
        "title": "Vérification de l'Installation",
        "devtools": "Ouvrez les DevTools (F12) et exécutez cette commande dans la console :",
        "shouldReturn": "Cela devrait retourner \"available\" si tout fonctionne correctement.",
        "checkDownload": "Vérifiez le statut de téléchargement du modèle à :",
        "lookFor": "Recherchez le composant \"Optimization Guide On Device Model\"."
      }
    },
    "troubleshooting": {
      "title": "Résolution de Problèmes",
      "apiNotFound": "API introuvable : Assurez-vous d'utiliser Chrome Canary/Dev et d'avoir activé les flags",
      "modelUnavailable": "Modèle indisponible : Vérifiez les exigences matérielles ou activez le bypass CPU",
      "downloadProblems": "Problèmes de téléchargement : Assurez-vous d'avoir suffisamment d'espace et une connexion illimitée",
      "stillNotWorking": "Toujours pas fonctionnel : Essayez de redémarrer Chrome et vérifiez chrome://components"
    },
    "footer": {
      "documentation": "Pour des informations plus détaillées, visitez la",
      "documentationLink": "documentation officielle de l'IA Chrome",
      "understood": "Compris ! Commençons",
      "tryAgain": "Réessayer"
    }
  },
  "footer": {
    "description": "Gemini Nano - Modèle de langage s'exécutant directement dans le navigateur"
  },
  "language": {
    "selector": "Langue"
  },
  "guide": {
    "title": "[fr] Gemini Nano Guide",
    "section1": {
      "title": "[fr] Introduction",
      "paragraph1": "[fr] This guide helps you get started with the Gemini Nano API integrated into this playground."
    },
    "section2": {
      "title": "[fr] What is Gemini Nano?",
      "paragraph1": "[fr] Gemini Nano is Google's most efficient model built for on-device tasks. It runs directly on user devices, leveraging hardware acceleration for fast and offline-capable AI features.",
      "paragraph2": "[fr] This version of Gemini Nano is integrated into Chrome and can be accessed via the `window.ai` API, allowing web developers to bring generative AI capabilities to their web applications."
    },
    "section3": {
      "title": "[fr] Key Features",
      "listItem1": "[fr] On-Device Processing: Ensures user privacy and enables offline functionality by running directly in the browser.",
      "listItem2": "[fr] Text Generation: Capable of generating coherent and contextually relevant text based on prompts.",
      "listItem3": "[fr] Efficiency: Optimized for resource-constrained environments, providing a balance between performance and model size.",
      "listItem4": "[fr] Web Platform Integration: Accessible through the `window.ai` API in Chrome, making it easy for web developers to use."
    },
    "section4": {
      "title": "[fr] How to Use This Playground",
      "paragraph1": "[fr] This playground provides an interactive way to test Gemini Nano's capabilities:",
      "listItem1": "[fr] Control Panel: Adjust model parameters like Temperature and Top-K to see how they affect the output. Initialize or restart the model if needed.",
      "listItem2": "[fr] Prompt Interface: Type your questions or instructions into the text area and click 'Send'. You can also try the provided prompt suggestions.",
      "listItem3": "[fr] Output Display: View the model's generated response. Note that generation can be stopped using the 'Stop' button.",
      "paragraph2": "[fr] Experiment with different prompts and settings to understand the model's behavior."
    },
    "section5": {
      "title": "[fr] Important Considerations",
      "paragraph1": "[fr] While Gemini Nano is powerful, keep these points in mind:",
      "listItem1": "[fr] Experimental Technology: This is an experimental feature. The API and model capabilities may change.",
      "listItem2": "[fr] Browser Compatibility: Currently, it's primarily available in Chrome versions that support the built-in AI SDK (e.g., Chrome Canary/Dev with specific flags enabled).",
      "listItem3": "[fr] Performance: Performance can vary based on your device hardware. The initial model download may take some time.",
      "listItem4": "[fr] Responsible AI: Generated content should be reviewed. Be mindful of potential biases or inaccuracies."
    },
    "section6": {
      "title": "[fr] Checking API Availability",
      "paragraph1": "[fr] Before attempting to use Gemini Nano, it's crucial to check if the API is available in the user's browser. This can be done by checking for the `window.LanguageModel` object and then calling its `availability()` method.",
      "paragraph2": "[fr] The `availability()` method returns a string indicating the current status, such as `available`, `readilyAvailable`, or `unavailable`. `readilyAvailable` means the model is downloaded and ready to use immediately. `available` may mean the model needs to be downloaded first.",
      "codeBlock1_Description": "[fr] Example of checking API availability:",
      "codeBlock1": "async function checkApi() {\n  if (window.LanguageModel) {\n    try {\n      const availability = await window.LanguageModel.availability();\n      console.log('API Availability:', availability);\n      // Update UI based on availability:\n      // 'available' - Model exists but may need a download.\n      // 'readilyAvailable' - Model is downloaded and ready.\n      // 'unavailable' - No model available / API disabled / not supported.\n      return availability;\n    } catch (error) {\n      console.error('Error checking API availability:', error);\n      return 'unavailable';\n    }\n  } else {\n    console.log('window.LanguageModel API not found.');\n    return 'unavailable';\n  }\n}\ncheckApi();"
    },
    "section7": {
      "title": "[fr] Creating a Model Session & Parameters",
      "paragraph1": "[fr] Once you've confirmed the API is available, you can create a model session. A session represents an instance of the language model with specific configurations.",
      "subsection1_title": "[fr] Model Parameters",
      "subsection1_paragraph1": "[fr] When creating a session, you can specify parameters to control the model's behavior:",
      "subsection1_listItem1": "[fr] `temperature`: Controls randomness. Higher values (e.g., 0.8) make output more random, lower values (e.g., 0.2) make it more deterministic. Default is often around 0.7.",
      "subsection1_listItem2": "[fr] `topK`: Narrows the model's choices to the `K` most likely next tokens. A lower `topK` (e.g., 3) makes the output more focused and less diverse. Default might be higher (e.g., 40).",
      "subsection1_paragraph2": "[fr] These parameters are usually set during session creation but some APIs might allow adjusting them later.",
      "codeBlock1_Description": "[fr] Example of creating a model session with parameters:",
      "codeBlock1": "async function createSession() {\n  if (!window.LanguageModel || await window.LanguageModel.availability() === 'unavailable') {\n    console.log('LanguageModel API not available or model unavailable.');\n    return null;\n  }\n  try {\n    const session = await window.LanguageModel.create({\n      temperature: 0.7, // Example temperature\n      topK: 40,         // Example topK\n      // Add other parameters like systemInstruction if supported/needed\n    });\n    console.log('Session created:', session);\n    return session;\n  } catch (error) {\n    console.error('Error creating session:', error);\n    return null;\n  }\n}\n// const mySession = await createSession();"
    },
    "section8": {
      "title": "[fr] Sending Prompts",
      "paragraph1": "[fr] After creating a session, you can send prompts to the model to get responses. There are two main ways to receive responses: as a single complete response or by streaming chunks of the response as they are generated.",
      "subsection1_title": "[fr] Simple Prompts (Full Response)",
      "subsection1_paragraph1": "[fr] For shorter interactions where you want the entire response at once, use the `prompt()` method. This method returns a promise that resolves with the full text generated by the model.",
      "codeBlock1_Description": "[fr] Example of sending a simple prompt:",
      "codeBlock1": "async function sendSimplePrompt(session, text) {\n  if (!session) {\n    console.error('Session not available.');\n    return;\n  }\n  try {\n    console.log('Sending prompt:', text);\n    const result = await session.prompt(text);\n    console.log('Full response:', result);\n    // Update your UI with the result\n  } catch (error) {\n    console.error('Error sending prompt:', error);\n  }\n}\n// Assuming 'mySession' is an active session:\n// sendSimplePrompt(mySession, \"Explain quantum physics in simple terms.\");",
      "subsection2_title": "[fr] Streaming Prompts (Chunks)",
      "subsection2_paragraph1": "[fr] For longer responses or real-time feedback, streaming is preferred. The `promptStreaming()` method returns an asynchronous iterable stream. You can loop through this stream to get chunks of text as the model generates them.",
      "codeBlock2_Description": "[fr] Example of sending a streaming prompt:",
      "codeBlock2": "async function sendStreamingPrompt(session, text) {\n  if (!session) {\n    console.error('Session not available.');\n    return;\n  }\n  try {\n    console.log('Sending streaming prompt:', text);\n    const stream = session.promptStreaming(text);\n    let fullResponse = '';\n    for await (const chunk of stream) {\n      console.log('Stream chunk:', chunk);\n      fullResponse += chunk;\n      // Update your UI with the chunk or accumulating fullResponse\n    }\n    console.log('Complete streamed response:', fullResponse);\n  } catch (error) {\n    console.error('Error sending streaming prompt:', error);\n  }\n}\n// Assuming 'mySession' is an active session:\n// sendStreamingPrompt(mySession, \"Write a short story about a robot exploring a new planet.\");"
    },
    "section9": {
      "title": "[fr] Model Downloads",
      "paragraph1": "[fr] The Gemini Nano model might need to be downloaded to the user's device before it can be used. The API's `availability()` method can return `'available'`, indicating a download might be necessary, or `'readilyAvailable'` if it's already downloaded.",
      "paragraph2": "[fr] This playground automatically handles the download process when you click 'Initialize Model'. You'll see a progress indicator. If you are building your own application, you would typically initiate a session creation, and the browser would handle the download if needed, possibly providing progress through API events if the spec supports it (the exact mechanism can vary).",
      "paragraph3": "[fr] Ensure users are aware that a download might occur, especially on metered connections. Providing clear feedback during this process is essential for a good user experience."
    },
    "section10": {
      "title": "[fr] Error Handling",
      "paragraph1": "[fr] It's important to implement robust error handling when working with the Gemini Nano API. Operations like checking availability, creating a session, or sending prompts can fail for various reasons (e.g., API disabled, no network, internal errors).",
      "paragraph2": "[fr] Always use `try...catch` blocks around asynchronous API calls to gracefully handle potential errors and provide feedback to the user.",
      "codeBlock1_Description": "[fr] General approach to error handling (conceptual):",
      "codeBlock1": "async function performAiTask() {\n  try {\n    // Example: Check availability\n    if (!window.LanguageModel || await window.LanguageModel.availability() === 'unavailable') {\n      throw new Error('AI Model is not available.');\n    }\n\n    // Example: Create session\n    const session = await window.LanguageModel.create({ /* params */ });\n    if (!session) {\n      throw new Error('Failed to create AI session.');\n    }\n\n    // Example: Send prompt\n    const response = await session.prompt(\"Your prompt here\");\n    // Process response\n\n  } catch (error) {\n    console.error(\"An error occurred:\", error.message);\n    // Update UI to inform the user (e.g., display error.message)\n  }\n}\n// performAiTask();",
      "paragraph3": "[fr] Inspect the error object for details. The API might throw specific error types or provide error codes in the future, which can help in diagnosing issues."
    }
  }
}
