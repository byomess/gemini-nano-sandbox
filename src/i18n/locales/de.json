{
  "header": {
    "title": "Gemini Nano Playground",
    "subtitle": "Testen Sie die Prompt API direkt in Ihrem Browser."
  },
  "controls": {
    "title": "Kontrollpanel",
    "subtitle": "Modelleinstellungen",
    "modelInfo": {
      "title": "Modellinformationen",
      "subtitle": "Modellstatistiken und Details",
      "maxTemperature": "Maximale Temperatur",
      "maxTopK": "Maximales Top-K",
      "defaultTemperature": "Standardtemperatur",
      "defaultTopK": "Standard Top-K"
    },
    "status": {
      "ready": "Bereit",
      "downloading": "Herunterladen",
      "initializing": "Initialisierung",
      "error": "Fehler",
      "unverified": "Überprüfung"
    },
    "temperature": {
      "label": "Temperatur",
      "description": "Kontrolliert die Kreativität der Antworten. Höhere Werte erzeugen kreativere und unvorhersagbarere Antworten."
    },
    "topK": {
      "label": "Top-K",
      "description": "Begrenzt die Anzahl der betrachteten Token. Niedrigere Werte erzeugen fokussiertere Antworten."
    },
    "buttons": {
      "start": "Modell Initialisieren",
      "restart": "Modell Neu Starten",
      "startSubtitle": "Das Modell initialisieren",
      "restartSubtitle": "Das Modell neu starten"
    },
    "download": {
      "title": "Modell-Download",
      "progress": "{{progress}}% abgeschlossen",
      "downloading": "Modell wird heruntergeladen...",
      "subtitle": "Erforderliche Dateien werden heruntergeladen"
    }
  },
  "status": {
    "idle": "Warten auf Initialisierung",
    "initializing": "Initialisierung...",
    "downloading": "Modell wird heruntergeladen. Dies kann einige Minuten dauern.",
    "ready": "Bereit zur Verwendung",
    "initialMessage": "Klicken Sie auf \"Starten\", um die Modellverfügbarkeit zu prüfen.",
    "checkingAvailability": "Überprüfen der Modellverfügbarkeit...",
    "modelUnavailable": "Modell nicht verfügbar. Überprüfen Sie die Hardware- und Systemanforderungen.",
    "creatingSession": "Modell verfügbar. Sitzung wird erstellt...",
    "downloadProgress": "Modell wird heruntergeladen: {{progress}}%",
    "sessionReady": "Sitzung bereit mit Temperatur={{temperature}} und Top-K={{topK}}.",
    "unknownError": "Unbekannter Fehler",
    "error": "Fehler",
    "apiNotFound": "LanguageModel API nicht gefunden. Stellen Sie sicher, dass Sie Chrome mit den richtigen Flags verwenden."
  },
  "app": {
    "setupTitle": "Gemini Nano einrichten",
    "downloadingTitle": "Modell herunterladen...",
    "initializingTitle": "Initialisierung...",
    "setupDescription": "Klicken Sie auf \"Start\" im Seitenpanel, um zu beginnen.",
    "downloadingDescription": "Das Modell wird im Hintergrund heruntergeladen.",
    "initializingDescription": "KI wird für die Nutzung vorbereitet.",
    "footer": {
      "showGuideLink": "[de] Show Gemini Nano Guide",
      "hideGuideLink": "[de] Hide Gemini Nano Guide"
    }
  },
  "prompt": {
    "placeholder": "Geben Sie hier Ihre Frage oder Ihren Prompt ein...",
    "send": "Senden",
    "stop": "Stoppen",
    "generating": "Antwort wird generiert...",
    "empty": "Die Antwort wird hier erscheinen...",
    "label": "Geben Sie Ihre Frage oder Ihren Prompt ein:",
    "characterCount": "Zeichen",
    "startPrompt": "Geben Sie Ihre Frage oben ein, um zu beginnen",
    "suggestions": {
      "title": "Prompt-Vorschläge:",
      "examples": [
        "Erklären Sie, wie künstliche Intelligenz funktioniert",
        "Erstellen Sie eine JavaScript-Funktion zum Sortieren von Arrays",
        "Was sind die besten React-Praktiken?",
        "Wie optimiert man die Web-Performance?"
      ]
    }
  },
  "output": {
    "error": "Fehler: {{message}}",
    "interrupted": "Generierung unterbrochen"
  },
  "errors": {
    "modelParamsLoad": "Modellparameter konnten nicht geladen werden:",
    "apiAvailabilityCheck": "Fehler beim Überprüfen der API-Verfügbarkeit:"
  },
  "setupModal": {
    "title": "Gemini Nano Einrichten",
    "copyToClipboard": "In die Zwischenablage kopieren",
    "closeModalLabel": "Modal schließen",
    "alert": {
      "title": "Gemini Nano API Nicht Verfügbar",
      "description": "Es scheint, dass die Gemini Nano API in Ihrem Browser nicht verfügbar ist. Dies kann daran liegen, dass Sie Chrome Canary/Dev nicht verwenden, experimentelle Flags nicht aktiviert sind oder Ihr System die Anforderungen nicht erfüllt."
    },
    "introduction": {
      "title": "Was ist Gemini Nano?",
      "description": "Gemini Nano ist Googles On-Device-KI-Modell, das lokal in Chrome ausgeführt wird. Es ermöglicht leistungsstarke KI-Funktionen, ohne Daten an externe Server zu senden, was Datenschutz und schnelle Antworten gewährleistet."
    },
    "requirements": {
      "title": "Systemanforderungen",
      "osLabel": "Betriebssystem:",
      "osValue": "Windows 10/11, macOS 13+, oder Linux",
      "storageLabel": "Speicherplatz:",
      "storageValue": "Mindestens 22 GB verfügbar",
      "gpuLabel": "GPU:",
      "gpuValue": "Über 4 GB VRAM (oder CPU-Bypass verwenden - siehe unten)",
      "networkLabel": "Netzwerk:",
      "networkValue": "Unbegrenzte Verbindung (für den Download)"
    },
    "steps": {
      "step1": {
        "title": "Chrome Canary oder Dev Channel herunterladen",
        "description": "Gemini Nano ist nur in experimentellen Chrome-Versionen verfügbar:",
        "downloadCanary": "Chrome Canary Herunterladen",
        "downloadDev": "Chrome Dev Herunterladen"
      },
      "step2": {
        "title": "Experimentelle Flags Aktivieren",
        "chromeFlags": "Öffnen Sie Chrome und navigieren Sie zur Flags-Seite:",
        "enableApi": "Gemini Nano API aktivieren:",
        "setFlagToEnabled": "Von \"Standard\" auf \"Aktiviert\" ändern",
        "restart": "Chrome neu starten:",
        "relaunchDescription": "Klicken Sie auf die Schaltfläche \"Neu starten\", die am unteren Rand der Seite erscheint."
      },
      "step3": {
        "title": "CPU-Verarbeitung (Optional)",
        "description": "Haben Sie keine dedizierte GPU mit 4+ GB VRAM? Aktivieren Sie die CPU-Verarbeitung mit diesem zusätzlichen Flag:",
        "searchFlag": "Suchen Sie nach diesem Flag und setzen Sie es auf \"Enabled\"",
        "ignoreGpu": "Dies ignoriert GPU-Anforderungen und verwendet die CPU",
        "performance": "Die Leistung kann langsamer sein, aber trotzdem funktional"
      },
      "step4": {
        "title": "Installationsverifikation",
        "devtools": "Öffnen Sie die DevTools (F12) und führen Sie diesen Befehl in der Konsole aus:",
        "shouldReturn": "Dies sollte \"available\" zurückgeben, wenn alles korrekt funktioniert.",
        "checkDownload": "Überprüfen Sie den Modell-Download-Status unter:",
        "lookFor": "Suchen Sie nach der Komponente \"Optimization Guide On Device Model\"."
      }
    },
    "troubleshooting": {
      "title": "Fehlerbehebung",
      "apiNotFound": "API nicht gefunden: Stellen Sie sicher, dass Sie Chrome Canary/Dev verwenden und die Flags aktiviert haben",
      "modelUnavailable": "Modell nicht verfügbar: Überprüfen Sie die Hardware-Anforderungen oder aktivieren Sie den CPU-Bypass",
      "downloadProblems": "Download-Probleme: Stellen Sie sicher, dass Sie genügend Speicherplatz und eine unbegrenzte Verbindung haben",
      "stillNotWorking": "Funktioniert immer noch nicht: Versuchen Sie Chrome neu zu starten und chrome://components zu überprüfen"
    },
    "footer": {
      "documentation": "Für detailliertere Informationen besuchen Sie die",
      "documentationLink": "offizielle Chrome AI Dokumentation",
      "understood": "Verstanden! Lassen Sie uns anfangen",
      "tryAgain": "Erneut Versuchen"
    }
  },
  "footer": {
    "description": "Gemini Nano - Sprachmodell läuft direkt im Browser"
  },
  "language": {
    "selector": "Sprache"
  },
  "guide": {
    "title": "[de] Gemini Nano Guide",
    "section1": {
      "title": "[de] Introduction",
      "paragraph1": "[de] This guide helps you get started with the Gemini Nano API integrated into this playground."
    },
    "section2": {
      "title": "[de] What is Gemini Nano?",
      "paragraph1": "[de] Gemini Nano is Google's most efficient model built for on-device tasks. It runs directly on user devices, leveraging hardware acceleration for fast and offline-capable AI features.",
      "paragraph2": "[de] This version of Gemini Nano is integrated into Chrome and can be accessed via the `window.ai` API, allowing web developers to bring generative AI capabilities to their web applications."
    },
    "section3": {
      "title": "[de] Key Features",
      "listItem1": "[de] On-Device Processing: Ensures user privacy and enables offline functionality by running directly in the browser.",
      "listItem2": "[de] Text Generation: Capable of generating coherent and contextually relevant text based on prompts.",
      "listItem3": "[de] Efficiency: Optimized for resource-constrained environments, providing a balance between performance and model size.",
      "listItem4": "[de] Web Platform Integration: Accessible through the `window.ai` API in Chrome, making it easy for web developers to use."
    },
    "section4": {
      "title": "[de] How to Use This Playground",
      "paragraph1": "[de] This playground provides an interactive way to test Gemini Nano's capabilities:",
      "listItem1": "[de] Control Panel: Adjust model parameters like Temperature and Top-K to see how they affect the output. Initialize or restart the model if needed.",
      "listItem2": "[de] Prompt Interface: Type your questions or instructions into the text area and click 'Send'. You can also try the provided prompt suggestions.",
      "listItem3": "[de] Output Display: View the model's generated response. Note that generation can be stopped using the 'Stop' button.",
      "paragraph2": "[de] Experiment with different prompts and settings to understand the model's behavior."
    },
    "section5": {
      "title": "[de] Important Considerations",
      "paragraph1": "[de] While Gemini Nano is powerful, keep these points in mind:",
      "listItem1": "[de] Experimental Technology: This is an experimental feature. The API and model capabilities may change.",
      "listItem2": "[de] Browser Compatibility: Currently, it's primarily available in Chrome versions that support the built-in AI SDK (e.g., Chrome Canary/Dev with specific flags enabled).",
      "listItem3": "[de] Performance: Performance can vary based on your device hardware. The initial model download may take some time.",
      "listItem4": "[de] Responsible AI: Generated content should be reviewed. Be mindful of potential biases or inaccuracies."
    },
    "section6": {
      "title": "[de] Checking API Availability",
      "paragraph1": "[de] Before attempting to use Gemini Nano, it's crucial to check if the API is available in the user's browser. This can be done by checking for the `window.LanguageModel` object and then calling its `availability()` method.",
      "paragraph2": "[de] The `availability()` method returns a string indicating the current status, such as `available`, `readilyAvailable`, or `unavailable`. `readilyAvailable` means the model is downloaded and ready to use immediately. `available` may mean the model needs to be downloaded first.",
      "codeBlock1_Description": "[de] Example of checking API availability:",
      "codeBlock1": "async function checkApi() {\n  if (window.LanguageModel) {\n    try {\n      const availability = await window.LanguageModel.availability();\n      console.log('API Availability:', availability);\n      // Update UI based on availability:\n      // 'available' - Model exists but may need a download.\n      // 'readilyAvailable' - Model is downloaded and ready.\n      // 'unavailable' - No model available / API disabled / not supported.\n      return availability;\n    } catch (error) {\n      console.error('Error checking API availability:', error);\n      return 'unavailable';\n    }\n  } else {\n    console.log('window.LanguageModel API not found.');\n    return 'unavailable';\n  }\n}\ncheckApi();"
    },
    "section7": {
      "title": "[de] Creating a Model Session & Parameters",
      "paragraph1": "[de] Once you've confirmed the API is available, you can create a model session. A session represents an instance of the language model with specific configurations.",
      "subsection1_title": "[de] Model Parameters",
      "subsection1_paragraph1": "[de] When creating a session, you can specify parameters to control the model's behavior:",
      "subsection1_listItem1": "[de] `temperature`: Controls randomness. Higher values (e.g., 0.8) make output more random, lower values (e.g., 0.2) make it more deterministic. Default is often around 0.7.",
      "subsection1_listItem2": "[de] `topK`: Narrows the model's choices to the `K` most likely next tokens. A lower `topK` (e.g., 3) makes the output more focused and less diverse. Default might be higher (e.g., 40).",
      "subsection1_paragraph2": "[de] These parameters are usually set during session creation but some APIs might allow adjusting them later.",
      "codeBlock1_Description": "[de] Example of creating a model session with parameters:",
      "codeBlock1": "async function createSession() {\n  if (!window.LanguageModel || await window.LanguageModel.availability() === 'unavailable') {\n    console.log('LanguageModel API not available or model unavailable.');\n    return null;\n  }\n  try {\n    const session = await window.LanguageModel.create({\n      temperature: 0.7, // Example temperature\n      topK: 40,         // Example topK\n      // Add other parameters like systemInstruction if supported/needed\n    });\n    console.log('Session created:', session);\n    return session;\n  } catch (error) {\n    console.error('Error creating session:', error);\n    return null;\n  }\n}\n// const mySession = await createSession();"
    },
    "section8": {
      "title": "[de] Sending Prompts",
      "paragraph1": "[de] After creating a session, you can send prompts to the model to get responses. There are two main ways to receive responses: as a single complete response or by streaming chunks of the response as they are generated.",
      "subsection1_title": "[de] Simple Prompts (Full Response)",
      "subsection1_paragraph1": "[de] For shorter interactions where you want the entire response at once, use the `prompt()` method. This method returns a promise that resolves with the full text generated by the model.",
      "codeBlock1_Description": "[de] Example of sending a simple prompt:",
      "codeBlock1": "async function sendSimplePrompt(session, text) {\n  if (!session) {\n    console.error('Session not available.');\n    return;\n  }\n  try {\n    console.log('Sending prompt:', text);\n    const result = await session.prompt(text);\n    console.log('Full response:', result);\n    // Update your UI with the result\n  } catch (error) {\n    console.error('Error sending prompt:', error);\n  }\n}\n// Assuming 'mySession' is an active session:\n// sendSimplePrompt(mySession, \"Explain quantum physics in simple terms.\");",
      "subsection2_title": "[de] Streaming Prompts (Chunks)",
      "subsection2_paragraph1": "[de] For longer responses or real-time feedback, streaming is preferred. The `promptStreaming()` method returns an asynchronous iterable stream. You can loop through this stream to get chunks of text as the model generates them.",
      "codeBlock2_Description": "[de] Example of sending a streaming prompt:",
      "codeBlock2": "async function sendStreamingPrompt(session, text) {\n  if (!session) {\n    console.error('Session not available.');\n    return;\n  }\n  try {\n    console.log('Sending streaming prompt:', text);\n    const stream = session.promptStreaming(text);\n    let fullResponse = '';\n    for await (const chunk of stream) {\n      console.log('Stream chunk:', chunk);\n      fullResponse += chunk;\n      // Update your UI with the chunk or accumulating fullResponse\n    }\n    console.log('Complete streamed response:', fullResponse);\n  } catch (error) {\n    console.error('Error sending streaming prompt:', error);\n  }\n}\n// Assuming 'mySession' is an active session:\n// sendStreamingPrompt(mySession, \"Write a short story about a robot exploring a new planet.\");"
    },
    "section9": {
      "title": "[de] Model Downloads",
      "paragraph1": "[de] The Gemini Nano model might need to be downloaded to the user's device before it can be used. The API's `availability()` method can return `'available'`, indicating a download might be necessary, or `'readilyAvailable'` if it's already downloaded.",
      "paragraph2": "[de] This playground automatically handles the download process when you click 'Initialize Model'. You'll see a progress indicator. If you are building your own application, you would typically initiate a session creation, and the browser would handle the download if needed, possibly providing progress through API events if the spec supports it (the exact mechanism can vary).",
      "paragraph3": "[de] Ensure users are aware that a download might occur, especially on metered connections. Providing clear feedback during this process is essential for a good user experience."
    },
    "section10": {
      "title": "[de] Error Handling",
      "paragraph1": "[de] It's important to implement robust error handling when working with the Gemini Nano API. Operations like checking availability, creating a session, or sending prompts can fail for various reasons (e.g., API disabled, no network, internal errors).",
      "paragraph2": "[de] Always use `try...catch` blocks around asynchronous API calls to gracefully handle potential errors and provide feedback to the user.",
      "codeBlock1_Description": "[de] General approach to error handling (conceptual):",
      "codeBlock1": "async function performAiTask() {\n  try {\n    // Example: Check availability\n    if (!window.LanguageModel || await window.LanguageModel.availability() === 'unavailable') {\n      throw new Error('AI Model is not available.');\n    }\n\n    // Example: Create session\n    const session = await window.LanguageModel.create({ /* params */ });\n    if (!session) {\n      throw new Error('Failed to create AI session.');\n    }\n\n    // Example: Send prompt\n    const response = await session.prompt(\"Your prompt here\");\n    // Process response\n\n  } catch (error) {\n    console.error(\"An error occurred:\", error.message);\n    // Update UI to inform the user (e.g., display error.message)\n  }\n}\n// performAiTask();",
      "paragraph3": "[de] Inspect the error object for details. The API might throw specific error types or provide error codes in the future, which can help in diagnosing issues."
    }
  }
}
