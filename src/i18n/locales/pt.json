{
  "header": {
    "title": "Gemini Nano Playground",
    "subtitle": "Teste a API Prompt diretamente no seu navegador."
  },
  "controls": {
    "title": "Painel de Controle",
    "subtitle": "Configurações do Modelo",
    "modelInfo": {
      "title": "Informações do Modelo",
      "subtitle": "Estatísticas e detalhes do modelo",
      "maxTemperature": "Temperatura Máxima",
      "maxTopK": "Top-K Máximo",
      "defaultTemperature": "Temperatura Padrão",
      "defaultTopK": "Top-K Padrão"
    },
    "status": {
      "ready": "Pronto",
      "downloading": "Baixando",
      "initializing": "Inicializando",
      "error": "Erro",
      "unverified": "Verificando"
    },
    "temperature": {
      "label": "Temperatura",
      "description": "Controla a criatividade das respostas. Valores mais altos geram respostas mais criativas e imprevisíveis."
    },
    "topK": {
      "label": "Top-K",
      "description": "Limita o número de tokens considerados. Valores menores geram respostas mais focadas."
    },
    "buttons": {
      "start": "Inicializar Modelo",
      "restart": "Reiniciar Modelo",
      "startSubtitle": "Inicializar o modelo",
      "restartSubtitle": "Reiniciar o modelo"
    },
    "download": {
      "title": "Download do Modelo",
      "progress": "{{progress}}% concluído",
      "downloading": "Fazendo download do modelo...",
      "subtitle": "Baixando arquivos necessários"
    }
  },
  "status": {
    "idle": "Aguardando inicialização",
    "initializing": "Inicializando...",
    "downloading": "Fazendo download do modelo. Isso pode levar alguns minutos.",
    "ready": "Pronto para uso",
    "initialMessage": "Clique em \"Iniciar\" para verificar a disponibilidade do modelo.",
    "checkingAvailability": "Verificando disponibilidade do modelo...",
    "modelUnavailable": "Modelo indisponível. Verifique os requisitos de hardware e sistema.",
    "creatingSession": "Modelo disponível. Criando sessão...",
    "downloadProgress": "Baixando modelo: {{progress}}%",
    "sessionReady": "Sessão pronta com Temperatura={{temperature}} e Top-K={{topK}}.",
    "unknownError": "Erro desconhecido",
    "error": "Erro: {{message}}",
    "apiNotFound": "API LanguageModel não encontrada. Certifique-se de que está no Chrome com as flags corretas."
  },
  "app": {
    "setupTitle": "Configure o Gemini Nano",
    "downloadingTitle": "Baixando modelo...",
    "initializingTitle": "Inicializando...",
    "setupDescription": "Clique em \"Iniciar\" no painel lateral para começar.",
    "downloadingDescription": "O modelo está sendo baixado em segundo plano.",
    "initializingDescription": "Preparando a IA para uso.",
    "footer": {
      "showGuideLink": "[pt] Show Gemini Nano Guide",
      "hideGuideLink": "[pt] Hide Gemini Nano Guide"
    }
  },
  "prompt": {
    "placeholder": "Digite sua pergunta ou prompt aqui...",
    "send": "Enviar",
    "stop": "Parar",
    "generating": "Gerando resposta...",
    "empty": "A resposta aparecerá aqui...",
    "label": "Digite sua pergunta ou prompt:",
    "characterCount": "caracteres",
    "startPrompt": "Digite sua pergunta acima para começar",
    "suggestions": {
      "title": "Sugestões de prompts:",
      "examples": [
        "Explique como funciona a inteligência artificial",
        "Crie uma função JavaScript para ordenar arrays",
        "Quais são as melhores práticas de React?",
        "Como otimizar performance web?"
      ]
    }
  },
  "output": {
    "error": "Erro: {{message}}",
    "interrupted": "Geração interrompida"
  },
  "errors": {
    "modelParamsLoad": "Não foi possível carregar os parâmetros do modelo:",
    "apiAvailabilityCheck": "Erro ao verificar disponibilidade da API:"
  },
  "setupModal": {
    "title": "Configurar Gemini Nano",
    "copyToClipboard": "Copiar para a área de transferência",
    "closeModalLabel": "Fechar modal",
    "alert": {
      "title": "API Gemini Nano Não Disponível",
      "description": "Parece que a API Gemini Nano não está disponível no seu navegador. Isso pode ser porque você não está usando o Chrome Canary/Dev, as flags experimentais não estão habilitadas, ou seu sistema não atende aos requisitos."
    },
    "introduction": {
      "title": "O que é Gemini Nano?",
      "description": "Gemini Nano é o modelo de IA no dispositivo do Google que roda localmente no Chrome. Ele permite recursos poderosos de IA sem enviar dados para servidores externos, garantindo privacidade e respostas rápidas."
    },
    "requirements": {
      "title": "Requisitos do Sistema",
      "osLabel": "Sistema Operacional:",
      "osValue": "Windows 10/11, macOS 13+, ou Linux",
      "storageLabel": "Armazenamento:",
      "storageValue": "Pelo menos 22 GB disponíveis",
      "gpuLabel": "GPU:",
      "gpuValue": "Mais de 4 GB VRAM (ou use bypass de CPU - veja abaixo)",
      "networkLabel": "Rede:",
      "networkValue": "Conexão ilimitada (para download)"
    },
    "steps": {
      "step1": {
        "title": "Obtenha o Chrome Canary ou Dev Channel",
        "description": "O Gemini Nano está disponível apenas em versões experimentais do Chrome:",
        "downloadCanary": "Download Chrome Canary",
        "downloadDev": "Download Chrome Dev"
      },
      "step2": {
        "title": "Habilite Flags Experimentais",
        "chromeFlags": "Abra o Chrome e navegue para a página de flags:",
        "enableApi": "Habilite a API Gemini Nano:",
        "setFlagToEnabled": "Mude de \"Padrão\" para \"Habilitado\"",
        "restart": "Reinicie o Chrome:",
        "relaunchDescription": "Clique no botão \"Reiniciar\" que aparece na parte inferior da página."
      },
      "step3": {
        "title": "Processamento via CPU (Opcional)",
        "description": "Não tem uma GPU dedicada com 4+ GB VRAM? Habilite o processamento via CPU com este flag adicional:",
        "searchFlag": "Busque por esse flag e defina como \"Enabled\"",
        "ignoreGpu": "Isso ignora os requisitos de GPU e usa a CPU",
        "performance": "O desempenho pode ser mais lento, mas ainda funcional"
      },
      "step4": {
        "title": "Verificação da Instalação",
        "devtools": "Abra o DevTools (F12) e execute este comando no console:",
        "shouldReturn": "Isso deve retornar \"available\" se tudo estiver funcionando corretamente.",
        "checkDownload": "Verifique o status de download do modelo em:",
        "lookFor": "Procure pelo componente \"Optimization Guide On Device Model\"."
      }
    },
    "troubleshooting": {
      "title": "Solução de Problemas",
      "apiNotFound": "API não encontrada: Certifique-se de estar usando Chrome Canary/Dev e ter habilitado os flags",
      "modelUnavailable": "Modelo indisponível: Verifique os requisitos de hardware ou habilite o bypass de CPU",
      "downloadProblems": "Problemas de download: Garanta que você tenha espaço suficiente e uma conexão ilimitada",
      "stillNotWorking": "Ainda não funciona: Tente reiniciar o Chrome e verificar chrome://components"
    },
    "footer": {
      "documentation": "Para informações mais detalhadas, visite a",
      "documentationLink": "documentação oficial de IA do Chrome",
      "understood": "Entendi! Vamos começar",
      "tryAgain": "Tentar Novamente"
    }
  },
  "footer": {
    "description": "Gemini Nano - Modelo de linguagem executado diretamente no navegador"
  },
  "language": {
    "selector": "Idioma"
  },
  "guide": {
    "title": "[pt] Gemini Nano Guide",
    "section1": {
      "title": "[pt] Introduction",
      "paragraph1": "[pt] This guide helps you get started with the Gemini Nano API integrated into this playground."
    },
    "section2": {
      "title": "[pt] What is Gemini Nano?",
      "paragraph1": "[pt] Gemini Nano is Google's most efficient model built for on-device tasks. It runs directly on user devices, leveraging hardware acceleration for fast and offline-capable AI features.",
      "paragraph2": "[pt] This version of Gemini Nano is integrated into Chrome and can be accessed via the `window.ai` API, allowing web developers to bring generative AI capabilities to their web applications."
    },
    "section3": {
      "title": "[pt] Key Features",
      "listItem1": "[pt] On-Device Processing: Ensures user privacy and enables offline functionality by running directly in the browser.",
      "listItem2": "[pt] Text Generation: Capable of generating coherent and contextually relevant text based on prompts.",
      "listItem3": "[pt] Efficiency: Optimized for resource-constrained environments, providing a balance between performance and model size.",
      "listItem4": "[pt] Web Platform Integration: Accessible through the `window.ai` API in Chrome, making it easy for web developers to use."
    },
    "section4": {
      "title": "[pt] How to Use This Playground",
      "paragraph1": "[pt] This playground provides an interactive way to test Gemini Nano's capabilities:",
      "listItem1": "[pt] Control Panel: Adjust model parameters like Temperature and Top-K to see how they affect the output. Initialize or restart the model if needed.",
      "listItem2": "[pt] Prompt Interface: Type your questions or instructions into the text area and click 'Send'. You can also try the provided prompt suggestions.",
      "listItem3": "[pt] Output Display: View the model's generated response. Note that generation can be stopped using the 'Stop' button.",
      "paragraph2": "[pt] Experiment with different prompts and settings to understand the model's behavior."
    },
    "section5": {
      "title": "[pt] Important Considerations",
      "paragraph1": "[pt] While Gemini Nano is powerful, keep these points in mind:",
      "listItem1": "[pt] Experimental Technology: This is an experimental feature. The API and model capabilities may change.",
      "listItem2": "[pt] Browser Compatibility: Currently, it's primarily available in Chrome versions that support the built-in AI SDK (e.g., Chrome Canary/Dev with specific flags enabled).",
      "listItem3": "[pt] Performance: Performance can vary based on your device hardware. The initial model download may take some time.",
      "listItem4": "[pt] Responsible AI: Generated content should be reviewed. Be mindful of potential biases or inaccuracies."
    },
    "section6": {
      "title": "[pt] Checking API Availability",
      "paragraph1": "[pt] Before attempting to use Gemini Nano, it's crucial to check if the API is available in the user's browser. This can be done by checking for the `window.LanguageModel` object and then calling its `availability()` method.",
      "paragraph2": "[pt] The `availability()` method returns a string indicating the current status, such as `available`, `readilyAvailable`, or `unavailable`. `readilyAvailable` means the model is downloaded and ready to use immediately. `available` may mean the model needs to be downloaded first.",
      "codeBlock1_Description": "[pt] Example of checking API availability:",
      "codeBlock1": "async function checkApi() {\n  if (window.LanguageModel) {\n    try {\n      const availability = await window.LanguageModel.availability();\n      console.log('API Availability:', availability);\n      // Update UI based on availability:\n      // 'available' - Model exists but may need a download.\n      // 'readilyAvailable' - Model is downloaded and ready.\n      // 'unavailable' - No model available / API disabled / not supported.\n      return availability;\n    } catch (error) {\n      console.error('Error checking API availability:', error);\n      return 'unavailable';\n    }\n  } else {\n    console.log('window.LanguageModel API not found.');\n    return 'unavailable';\n  }\n}\ncheckApi();"
    },
    "section7": {
      "title": "[pt] Creating a Model Session & Parameters",
      "paragraph1": "[pt] Once you've confirmed the API is available, you can create a model session. A session represents an instance of the language model with specific configurations.",
      "subsection1_title": "[pt] Model Parameters",
      "subsection1_paragraph1": "[pt] When creating a session, you can specify parameters to control the model's behavior:",
      "subsection1_listItem1": "[pt] `temperature`: Controls randomness. Higher values (e.g., 0.8) make output more random, lower values (e.g., 0.2) make it more deterministic. Default is often around 0.7.",
      "subsection1_listItem2": "[pt] `topK`: Narrows the model's choices to the `K` most likely next tokens. A lower `topK` (e.g., 3) makes the output more focused and less diverse. Default might be higher (e.g., 40).",
      "subsection1_paragraph2": "[pt] These parameters are usually set during session creation but some APIs might allow adjusting them later.",
      "codeBlock1_Description": "[pt] Example of creating a model session with parameters:",
      "codeBlock1": "async function createSession() {\n  if (!window.LanguageModel || await window.LanguageModel.availability() === 'unavailable') {\n    console.log('LanguageModel API not available or model unavailable.');\n    return null;\n  }\n  try {\n    const session = await window.LanguageModel.create({\n      temperature: 0.7, // Example temperature\n      topK: 40,         // Example topK\n      // Add other parameters like systemInstruction if supported/needed\n    });\n    console.log('Session created:', session);\n    return session;\n  } catch (error) {\n    console.error('Error creating session:', error);\n    return null;\n  }\n}\n// const mySession = await createSession();"
    },
    "section8": {
      "title": "[pt] Sending Prompts",
      "paragraph1": "[pt] After creating a session, you can send prompts to the model to get responses. There are two main ways to receive responses: as a single complete response or by streaming chunks of the response as they are generated.",
      "subsection1_title": "[pt] Simple Prompts (Full Response)",
      "subsection1_paragraph1": "[pt] For shorter interactions where you want the entire response at once, use the `prompt()` method. This method returns a promise that resolves with the full text generated by the model.",
      "codeBlock1_Description": "[pt] Example of sending a simple prompt:",
      "codeBlock1": "async function sendSimplePrompt(session, text) {\n  if (!session) {\n    console.error('Session not available.');\n    return;\n  }\n  try {\n    console.log('Sending prompt:', text);\n    const result = await session.prompt(text);\n    console.log('Full response:', result);\n    // Update your UI with the result\n  } catch (error) {\n    console.error('Error sending prompt:', error);\n  }\n}\n// Assuming 'mySession' is an active session:\n// sendSimplePrompt(mySession, \"Explain quantum physics in simple terms.\");",
      "subsection2_title": "[pt] Streaming Prompts (Chunks)",
      "subsection2_paragraph1": "[pt] For longer responses or real-time feedback, streaming is preferred. The `promptStreaming()` method returns an asynchronous iterable stream. You can loop through this stream to get chunks of text as the model generates them.",
      "codeBlock2_Description": "[pt] Example of sending a streaming prompt:",
      "codeBlock2": "async function sendStreamingPrompt(session, text) {\n  if (!session) {\n    console.error('Session not available.');\n    return;\n  }\n  try {\n    console.log('Sending streaming prompt:', text);\n    const stream = session.promptStreaming(text);\n    let fullResponse = '';\n    for await (const chunk of stream) {\n      console.log('Stream chunk:', chunk);\n      fullResponse += chunk;\n      // Update your UI with the chunk or accumulating fullResponse\n    }\n    console.log('Complete streamed response:', fullResponse);\n  } catch (error) {\n    console.error('Error sending streaming prompt:', error);\n  }\n}\n// Assuming 'mySession' is an active session:\n// sendStreamingPrompt(mySession, \"Write a short story about a robot exploring a new planet.\");"
    },
    "section9": {
      "title": "[pt] Model Downloads",
      "paragraph1": "[pt] The Gemini Nano model might need to be downloaded to the user's device before it can be used. The API's `availability()` method can return `'available'`, indicating a download might be necessary, or `'readilyAvailable'` if it's already downloaded.",
      "paragraph2": "[pt] This playground automatically handles the download process when you click 'Initialize Model'. You'll see a progress indicator. If you are building your own application, you would typically initiate a session creation, and the browser would handle the download if needed, possibly providing progress through API events if the spec supports it (the exact mechanism can vary).",
      "paragraph3": "[pt] Ensure users are aware that a download might occur, especially on metered connections. Providing clear feedback during this process is essential for a good user experience."
    },
    "section10": {
      "title": "[pt] Error Handling",
      "paragraph1": "[pt] It's important to implement robust error handling when working with the Gemini Nano API. Operations like checking availability, creating a session, or sending prompts can fail for various reasons (e.g., API disabled, no network, internal errors).",
      "paragraph2": "[pt] Always use `try...catch` blocks around asynchronous API calls to gracefully handle potential errors and provide feedback to the user.",
      "codeBlock1_Description": "[pt] General approach to error handling (conceptual):",
      "codeBlock1": "async function performAiTask() {\n  try {\n    // Example: Check availability\n    if (!window.LanguageModel || await window.LanguageModel.availability() === 'unavailable') {\n      throw new Error('AI Model is not available.');\n    }\n\n    // Example: Create session\n    const session = await window.LanguageModel.create({ /* params */ });\n    if (!session) {\n      throw new Error('Failed to create AI session.');\n    }\n\n    // Example: Send prompt\n    const response = await session.prompt(\"Your prompt here\");\n    // Process response\n\n  } catch (error) {\n    console.error(\"An error occurred:\", error.message);\n    // Update UI to inform the user (e.g., display error.message)\n  }\n}\n// performAiTask();",
      "paragraph3": "[pt] Inspect the error object for details. The API might throw specific error types or provide error codes in the future, which can help in diagnosing issues."
    }
  }
}
