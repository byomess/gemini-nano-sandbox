{
  "header": {
    "title": "Gemini Nano Playground",
    "subtitle": "Prueba la API de Prompt directamente en tu navegador."
  },
  "controls": {
    "title": "Panel de Control",
    "subtitle": "Configuración del Modelo",
    "modelInfo": {
      "title": "Información del Modelo",
      "subtitle": "Estadísticas y detalles del modelo",
      "maxTemperature": "Temperatura Máxima",
      "maxTopK": "Top-K Máximo",
      "defaultTemperature": "Temperatura por Defecto",
      "defaultTopK": "Top-K por Defecto"
    },
    "status": {
      "ready": "Listo",
      "downloading": "Descargando",
      "initializing": "Inicializando",
      "error": "Error",
      "unverified": "Verificando"
    },
    "temperature": {
      "label": "Temperatura",
      "description": "Controla la creatividad de las respuestas. Valores más altos generan respuestas más creativas e impredecibles."
    },
    "topK": {
      "label": "Top-K",
      "description": "Limita el número de tokens considerados. Valores menores generan respuestas más enfocadas."
    },
    "buttons": {
      "start": "Inicializar Modelo",
      "restart": "Reiniciar Modelo",
      "startSubtitle": "Inicializar el modelo",
      "restartSubtitle": "Reiniciar el modelo"
    },
    "download": {
      "title": "Descarga del Modelo",
      "progress": "{{progress}}% completado",
      "downloading": "Descargando modelo...",
      "subtitle": "Descargando archivos necesarios"
    }
  },
  "status": {
    "idle": "Esperando inicialización",
    "initializing": "Inicializando...",
    "downloading": "Descargando modelo. Esto puede tomar algunos minutos.",
    "ready": "Listo para usar",
    "initialMessage": "Haz clic en \"Iniciar\" para verificar disponibilidad del modelo.",
    "checkingAvailability": "Verificando disponibilidad del modelo...",
    "modelUnavailable": "Modelo no disponible. Verifica los requisitos de hardware y sistema.",
    "creatingSession": "Modelo disponible. Creando sesión...",
    "downloadProgress": "Descargando modelo: {{progress}}%",
    "sessionReady": "Sesión lista con Temperatura={{temperature}} y Top-K={{topK}}.",
    "unknownError": "Error desconocido",
    "error": "Error: {{message}}",
    "apiNotFound": "API LanguageModel no encontrada. Asegúrate de estar en Chrome con las flags correctas."
  },
  "app": {
    "setupTitle": "Configurar Gemini Nano",
    "downloadingTitle": "Descargando modelo...",
    "initializingTitle": "Inicializando...",
    "setupDescription": "Haz clic en \"Iniciar\" en el panel lateral para comenzar.",
    "downloadingDescription": "El modelo se está descargando en segundo plano.",
    "initializingDescription": "Preparando la IA para su uso.",
    "footer": {
      "showGuideLink": "[es] Show Gemini Nano Guide",
      "hideGuideLink": "[es] Hide Gemini Nano Guide"
    }
  },
  "prompt": {
    "placeholder": "Escribe tu pregunta o prompt aquí...",
    "send": "Enviar",
    "stop": "Detener",
    "generating": "Generando respuesta...",
    "empty": "La respuesta aparecerá aquí...",
    "label": "Escribe tu pregunta o prompt:",
    "characterCount": "caracteres",
    "startPrompt": "Escribe tu pregunta arriba para comenzar",
    "suggestions": {
      "title": "Sugerencias de prompts:",
      "examples": [
        "Explica cómo funciona la inteligencia artificial",
        "Crea una función JavaScript para ordenar arrays",
        "¿Cuáles son las mejores prácticas de React?",
        "¿Cómo optimizar el rendimiento web?"
      ]
    }
  },
  "output": {
    "error": "Error: {{message}}",
    "interrupted": "Generación interrumpida"
  },
  "errors": {
    "modelParamsLoad": "No se pudieron cargar los parámetros del modelo:",
    "apiAvailabilityCheck": "Error verificando disponibilidad de la API:"
  },
  "setupModal": {
    "title": "Configurar Gemini Nano",
    "copyToClipboard": "Copiar al portapapeles",
    "closeModalLabel": "Cerrar modal",
    "alert": {
      "title": "API de Gemini Nano No Disponible",
      "description": "Parece que la API de Gemini Nano no está disponible en tu navegador. Esto puede deberse a que no estás usando Chrome Canary/Dev, las flags experimentales no están habilitadas o tu sistema no cumple con los requisitos."
    },
    "introduction": {
      "title": "¿Qué es Gemini Nano?",
      "description": "Gemini Nano es el modelo de IA en el dispositivo de Google que se ejecuta localmente en Chrome. Permite potentes funciones de IA sin enviar datos a servidores externos, garantizando privacidad y respuestas rápidas."
    },
    "requirements": {
      "title": "Requisitos del Sistema",
      "osLabel": "Sistema Operativo:",
      "osValue": "Windows 10/11, macOS 13+, o Linux",
      "storageLabel": "Almacenamiento:",
      "storageValue": "Al menos 22 GB disponibles",
      "gpuLabel": "GPU:",
      "gpuValue": "Más de 4 GB VRAM (o usa bypass de CPU - ver abajo)",
      "networkLabel": "Red:",
      "networkValue": "Conexión ilimitada (para descarga)"
    },
    "steps": {
      "step1": {
        "title": "Obtén Chrome Canary o Dev Channel",
        "description": "Gemini Nano solo está disponible en versiones experimentales de Chrome:",
        "downloadCanary": "Descargar Chrome Canary",
        "downloadDev": "Descargar Chrome Dev"
      },
      "step2": {
        "title": "Habilitar Flags Experimentales",
        "chromeFlags": "Abre Chrome y navega a la página de flags:",
        "enableApi": "Habilita la API de Gemini Nano:",
        "setFlagToEnabled": "Cambia de \"Predeterminado\" a \"Habilitado\"",
        "restart": "Reinicia Chrome:",
        "relaunchDescription": "Haz clic en el botón \"Reiniciar\" que aparece en la parte inferior de la página."
      },
      "step3": {
        "title": "Procesamiento por CPU (Opcional)",
        "description": "¿No tienes una GPU dedicada con 4+ GB VRAM? Habilita el procesamiento por CPU con este flag adicional:",
        "searchFlag": "Busca este flag y configúralo como \"Enabled\"",
        "ignoreGpu": "Esto ignora los requisitos de GPU y usa la CPU",
        "performance": "El rendimiento puede ser más lento, pero aún funcional"
      },
      "step4": {
        "title": "Verificación de la Instalación",
        "devtools": "Abre las DevTools (F12) y ejecuta este comando en la consola:",
        "shouldReturn": "Esto debería devolver \"available\" si todo está funcionando correctamente.",
        "checkDownload": "Verifica el estado de descarga del modelo en:",
        "lookFor": "Busca el componente \"Optimization Guide On Device Model\"."
      }
    },
    "troubleshooting": {
      "title": "Solución de Problemas",
      "apiNotFound": "API no encontrada: Asegúrate de estar usando Chrome Canary/Dev y haber habilitado los flags",
      "modelUnavailable": "Modelo no disponible: Verifica los requisitos de hardware o habilita el bypass de CPU",
      "downloadProblems": "Problemas de descarga: Asegúrate de tener suficiente espacio y una conexión ilimitada",
      "stillNotWorking": "Aún no funciona: Intenta reiniciar Chrome y verificar chrome://components"
    },
    "footer": {
      "documentation": "Para información más detallada, visita la",
      "documentationLink": "documentación oficial de IA de Chrome",
      "understood": "¡Entendido! Vamos a empezar",
      "tryAgain": "Intentar de Nuevo"
    }
  },
  "footer": {
    "description": "Gemini Nano - Modelo de lenguaje ejecutándose directamente en el navegador"
  },
  "language": {
    "selector": "Idioma"
  },
  "guide": {
    "title": "[es] Gemini Nano Guide",
    "section1": {
      "title": "[es] Introduction",
      "paragraph1": "[es] This guide helps you get started with the Gemini Nano API integrated into this playground."
    },
    "section2": {
      "title": "[es] What is Gemini Nano?",
      "paragraph1": "[es] Gemini Nano is Google's most efficient model built for on-device tasks. It runs directly on user devices, leveraging hardware acceleration for fast and offline-capable AI features.",
      "paragraph2": "[es] This version of Gemini Nano is integrated into Chrome and can be accessed via the `window.ai` API, allowing web developers to bring generative AI capabilities to their web applications."
    },
    "section3": {
      "title": "[es] Key Features",
      "listItem1": "[es] On-Device Processing: Ensures user privacy and enables offline functionality by running directly in the browser.",
      "listItem2": "[es] Text Generation: Capable of generating coherent and contextually relevant text based on prompts.",
      "listItem3": "[es] Efficiency: Optimized for resource-constrained environments, providing a balance between performance and model size.",
      "listItem4": "[es] Web Platform Integration: Accessible through the `window.ai` API in Chrome, making it easy for web developers to use."
    },
    "section4": {
      "title": "[es] How to Use This Playground",
      "paragraph1": "[es] This playground provides an interactive way to test Gemini Nano's capabilities:",
      "listItem1": "[es] Control Panel: Adjust model parameters like Temperature and Top-K to see how they affect the output. Initialize or restart the model if needed.",
      "listItem2": "[es] Prompt Interface: Type your questions or instructions into the text area and click 'Send'. You can also try the provided prompt suggestions.",
      "listItem3": "[es] Output Display: View the model's generated response. Note that generation can be stopped using the 'Stop' button.",
      "paragraph2": "[es] Experiment with different prompts and settings to understand the model's behavior."
    },
    "section5": {
      "title": "[es] Important Considerations",
      "paragraph1": "[es] While Gemini Nano is powerful, keep these points in mind:",
      "listItem1": "[es] Experimental Technology: This is an experimental feature. The API and model capabilities may change.",
      "listItem2": "[es] Browser Compatibility: Currently, it's primarily available in Chrome versions that support the built-in AI SDK (e.g., Chrome Canary/Dev with specific flags enabled).",
      "listItem3": "[es] Performance: Performance can vary based on your device hardware. The initial model download may take some time.",
      "listItem4": "[es] Responsible AI: Generated content should be reviewed. Be mindful of potential biases or inaccuracies."
    },
    "section6": {
      "title": "[es] Checking API Availability",
      "paragraph1": "[es] Before attempting to use Gemini Nano, it's crucial to check if the API is available in the user's browser. This can be done by checking for the `window.LanguageModel` object and then calling its `availability()` method.",
      "paragraph2": "[es] The `availability()` method returns a string indicating the current status, such as `available`, `readilyAvailable`, or `unavailable`. `readilyAvailable` means the model is downloaded and ready to use immediately. `available` may mean the model needs to be downloaded first.",
      "codeBlock1_Description": "[es] Example of checking API availability:",
      "codeBlock1": "async function checkApi() {\n  if (window.LanguageModel) {\n    try {\n      const availability = await window.LanguageModel.availability();\n      console.log('API Availability:', availability);\n      // Update UI based on availability:\n      // 'available' - Model exists but may need a download.\n      // 'readilyAvailable' - Model is downloaded and ready.\n      // 'unavailable' - No model available / API disabled / not supported.\n      return availability;\n    } catch (error) {\n      console.error('Error checking API availability:', error);\n      return 'unavailable';\n    }\n  } else {\n    console.log('window.LanguageModel API not found.');\n    return 'unavailable';\n  }\n}\ncheckApi();"
    },
    "section7": {
      "title": "[es] Creating a Model Session & Parameters",
      "paragraph1": "[es] Once you've confirmed the API is available, you can create a model session. A session represents an instance of the language model with specific configurations.",
      "subsection1_title": "[es] Model Parameters",
      "subsection1_paragraph1": "[es] When creating a session, you can specify parameters to control the model's behavior:",
      "subsection1_listItem1": "[es] `temperature`: Controls randomness. Higher values (e.g., 0.8) make output more random, lower values (e.g., 0.2) make it more deterministic. Default is often around 0.7.",
      "subsection1_listItem2": "[es] `topK`: Narrows the model's choices to the `K` most likely next tokens. A lower `topK` (e.g., 3) makes the output more focused and less diverse. Default might be higher (e.g., 40).",
      "subsection1_paragraph2": "[es] These parameters are usually set during session creation but some APIs might allow adjusting them later.",
      "codeBlock1_Description": "[es] Example of creating a model session with parameters:",
      "codeBlock1": "async function createSession() {\n  if (!window.LanguageModel || await window.LanguageModel.availability() === 'unavailable') {\n    console.log('LanguageModel API not available or model unavailable.');\n    return null;\n  }\n  try {\n    const session = await window.LanguageModel.create({\n      temperature: 0.7, // Example temperature\n      topK: 40,         // Example topK\n      // Add other parameters like systemInstruction if supported/needed\n    });\n    console.log('Session created:', session);\n    return session;\n  } catch (error) {\n    console.error('Error creating session:', error);\n    return null;\n  }\n}\n// const mySession = await createSession();"
    },
    "section8": {
      "title": "[es] Sending Prompts",
      "paragraph1": "[es] After creating a session, you can send prompts to the model to get responses. There are two main ways to receive responses: as a single complete response or by streaming chunks of the response as they are generated.",
      "subsection1_title": "[es] Simple Prompts (Full Response)",
      "subsection1_paragraph1": "[es] For shorter interactions where you want the entire response at once, use the `prompt()` method. This method returns a promise that resolves with the full text generated by the model.",
      "codeBlock1_Description": "[es] Example of sending a simple prompt:",
      "codeBlock1": "async function sendSimplePrompt(session, text) {\n  if (!session) {\n    console.error('Session not available.');\n    return;\n  }\n  try {\n    console.log('Sending prompt:', text);\n    const result = await session.prompt(text);\n    console.log('Full response:', result);\n    // Update your UI with the result\n  } catch (error) {\n    console.error('Error sending prompt:', error);\n  }\n}\n// Assuming 'mySession' is an active session:\n// sendSimplePrompt(mySession, \"Explain quantum physics in simple terms.\");",
      "subsection2_title": "[es] Streaming Prompts (Chunks)",
      "subsection2_paragraph1": "[es] For longer responses or real-time feedback, streaming is preferred. The `promptStreaming()` method returns an asynchronous iterable stream. You can loop through this stream to get chunks of text as the model generates them.",
      "codeBlock2_Description": "[es] Example of sending a streaming prompt:",
      "codeBlock2": "async function sendStreamingPrompt(session, text) {\n  if (!session) {\n    console.error('Session not available.');\n    return;\n  }\n  try {\n    console.log('Sending streaming prompt:', text);\n    const stream = session.promptStreaming(text);\n    let fullResponse = '';\n    for await (const chunk of stream) {\n      console.log('Stream chunk:', chunk);\n      fullResponse += chunk;\n      // Update your UI with the chunk or accumulating fullResponse\n    }\n    console.log('Complete streamed response:', fullResponse);\n  } catch (error) {\n    console.error('Error sending streaming prompt:', error);\n  }\n}\n// Assuming 'mySession' is an active session:\n// sendStreamingPrompt(mySession, \"Write a short story about a robot exploring a new planet.\");"
    },
    "section9": {
      "title": "[es] Model Downloads",
      "paragraph1": "[es] The Gemini Nano model might need to be downloaded to the user's device before it can be used. The API's `availability()` method can return `'available'`, indicating a download might be necessary, or `'readilyAvailable'` if it's already downloaded.",
      "paragraph2": "[es] This playground automatically handles the download process when you click 'Initialize Model'. You'll see a progress indicator. If you are building your own application, you would typically initiate a session creation, and the browser would handle the download if needed, possibly providing progress through API events if the spec supports it (the exact mechanism can vary).",
      "paragraph3": "[es] Ensure users are aware that a download might occur, especially on metered connections. Providing clear feedback during this process is essential for a good user experience."
    },
    "section10": {
      "title": "[es] Error Handling",
      "paragraph1": "[es] It's important to implement robust error handling when working with the Gemini Nano API. Operations like checking availability, creating a session, or sending prompts can fail for various reasons (e.g., API disabled, no network, internal errors).",
      "paragraph2": "[es] Always use `try...catch` blocks around asynchronous API calls to gracefully handle potential errors and provide feedback to the user.",
      "codeBlock1_Description": "[es] General approach to error handling (conceptual):",
      "codeBlock1": "async function performAiTask() {\n  try {\n    // Example: Check availability\n    if (!window.LanguageModel || await window.LanguageModel.availability() === 'unavailable') {\n      throw new Error('AI Model is not available.');\n    }\n\n    // Example: Create session\n    const session = await window.LanguageModel.create({ /* params */ });\n    if (!session) {\n      throw new Error('Failed to create AI session.');\n    }\n\n    // Example: Send prompt\n    const response = await session.prompt(\"Your prompt here\");\n    // Process response\n\n  } catch (error) {\n    console.error(\"An error occurred:\", error.message);\n    // Update UI to inform the user (e.g., display error.message)\n  }\n}\n// performAiTask();",
      "paragraph3": "[es] Inspect the error object for details. The API might throw specific error types or provide error codes in the future, which can help in diagnosing issues."
    }
  }
}
