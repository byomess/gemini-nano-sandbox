{
  "header": {
    "title": "Gemini Nano Playground",
    "subtitle": "Test the Prompt API directly in your browser."
  },
  "controls": {
    "title": "Control Panel",
    "subtitle": "Model Settings",
    "modelInfo": {
      "title": "Model Information",
      "subtitle": "Model statistics and details",
      "maxTemperature": "Max Temperature",
      "maxTopK": "Max Top-K",
      "defaultTemperature": "Default Temperature",
      "defaultTopK": "Default Top-K"
    },
    "status": {
      "ready": "Ready",
      "downloading": "Downloading",
      "initializing": "Initializing",
      "error": "Error",
      "unverified": "Checking"
    },
    "temperature": {
      "label": "Temperature",
      "description": "Controls response creativity. Higher values generate more creative and unpredictable responses."
    },
    "topK": {
      "label": "Top-K",
      "description": "Limits the number of tokens considered. Lower values generate more focused responses."
    },
    "buttons": {
      "start": "Initialize Model",
      "restart": "Restart Model",
      "startSubtitle": "Initialize the model",
      "restartSubtitle": "Restart the model"
    },
    "download": {
      "title": "Model Download",
      "progress": "{{progress}}% completed",
      "downloading": "Downloading model...",
      "subtitle": "Downloading required files"
    }
  },
  "status": {
    "idle": "Waiting for initialization",
    "initializing": "Initializing...",
    "downloading": "Downloading model. This may take a few minutes.",
    "ready": "Ready to use",
    "initialMessage": "Click \"Start\" to check model availability.",
    "checkingAvailability": "Checking model availability...",
    "modelUnavailable": "Model unavailable. Check hardware and system requirements.",
    "creatingSession": "Model available. Creating session...",
    "downloadProgress": "Downloading model: {{progress}}%",
    "sessionReady": "Session ready with Temperature={{temperature}} and Top-K={{topK}}.",
    "unknownError": "Unknown error",
    "error": "Error: {{message}}",
    "apiNotFound": "LanguageModel API not found. Make sure you're in Chrome with the correct flags."
  },
  "app": {
    "setupTitle": "Setup Gemini Nano",
    "downloadingTitle": "Downloading model...",
    "initializingTitle": "Initializing...",
    "setupDescription": "Click \"Start\" on the side panel to begin.",
    "downloadingDescription": "The model is being downloaded in the background.",
    "initializingDescription": "Preparing AI for use.",
    "footer": {
      "showGuideLink": "Show Gemini Nano Guide",
      "hideGuideLink": "Hide Gemini Nano Guide"
    }
  },
  "prompt": {
    "placeholder": "Type your question or prompt here...",
    "send": "Send",
    "stop": "Stop",
    "generating": "Generating response...",
    "empty": "The response will appear here...",
    "label": "Type your question or prompt:",
    "characterCount": "characters",
    "startPrompt": "Type your question above to get started",
    "suggestions": {
      "title": "Prompt suggestions:",
      "examples": [
        "Explain how artificial intelligence works",
        "Create a JavaScript function to sort arrays",
        "What are React best practices?",
        "How to optimize web performance?"
      ]
    }
  },
  "output": {
    "error": "Error: {{message}}",
    "interrupted": "Generation interrupted"
  },
  "errors": {
    "modelParamsLoad": "Could not load model parameters:",
    "apiAvailabilityCheck": "Error checking API availability:"
  },
  "setupModal": {
    "title": "Setup Gemini Nano",
    "copyToClipboard": "Copy to clipboard",
    "closeModalLabel": "Close modal",
    "alert": {
      "title": "Gemini Nano API Not Available",
      "description": "It seems the Gemini Nano API is not available in your browser. This may be because you are not using Chrome Canary/Dev, experimental flags are not enabled, or your system does not meet the requirements."
    },
    "introduction": {
      "title": "What is Gemini Nano?",
      "description": "Gemini Nano is Google's on-device AI model that runs locally in Chrome. It enables powerful AI features without sending data to external servers, ensuring privacy and fast responses."
    },
    "requirements": {
      "title": "System Requirements",
      "osLabel": "Operating System:",
      "osValue": "Windows 10/11, macOS 13+, or Linux",
      "storageLabel": "Storage:",
      "storageValue": "At least 22 GB available",
      "gpuLabel": "GPU:",
      "gpuValue": "Over 4 GB VRAM (or use CPU bypass - see below)",
      "networkLabel": "Network:",
      "networkValue": "Unmetered/unlimited connection for download"
    },
    "steps": {
      "step1": {
        "title": "Get Chrome Canary or Dev Channel",
        "description": "You need Chrome Canary or Dev channel to access experimental AI features:",
        "downloadCanary": "Download Chrome Canary",
        "downloadDev": "Download Chrome Dev"
      },
      "step2": {
        "title": "Enable Experimental Flags",
        "chromeFlags": "Open Chrome and navigate to the flags page:",
        "enableApi": "Enable Gemini Nano API:",
        "setFlagToEnabled": "Change from \"Default\" to \"Enabled\"",
        "restart": "Restart Chrome:",
        "relaunchDescription": "Click the \"Relaunch\" button that appears at the bottom of the page."
      },
      "step3": {
        "title": "CPU Processing (Optional)",
        "description": "Don't have a dedicated GPU with 4+ GB VRAM? Enable CPU processing with this additional flag:",
        "searchFlag": "Search for this flag and set it to \"Enabled\"",
        "ignoreGpu": "This ignores GPU requirements and uses CPU",
        "performance": "Performance may be slower, but still functional"
      },
      "step4": {
        "title": "Installation Verification",
        "devtools": "Open DevTools (F12) and execute this command in the console:",
        "shouldReturn": "This should return \"available\" if everything is working correctly.",
        "checkDownload": "Check the model download status at:",
        "lookFor": "Look for the \"Optimization Guide On Device Model\" component."
      }
    },
    "troubleshooting": {
      "title": "Troubleshooting",
      "apiNotFound": "API not found: Ensure you are using Chrome Canary/Dev and have enabled the flags.",
      "modelUnavailable": "Model unavailable: Check hardware requirements or enable CPU bypass.",
      "downloadProblems": "Download problems: Ensure you have enough space and an unmetered connection.",
      "stillNotWorking": "Still not working: Try restarting Chrome and checking chrome://components."
    },
    "footer": {
      "documentation": "For more detailed information, visit the",
      "documentationLink": "official Chrome AI documentation",
      "understood": "Got it! Let's start",
      "tryAgain": "Try Again"
    }
  },
  "footer": {
    "description": "Gemini Nano - Language model running directly in the browser"
  },
  "language": {
    "selector": "Language"
  },
  "guide": {
    "title": "Gemini Nano Guide",
    "section1": {
      "title": "Introduction",
      "paragraph1": "This guide helps you get started with the Gemini Nano API integrated into this playground."
    },
    "section2": {
      "title": "What is Gemini Nano?",
      "paragraph1": "Gemini Nano is Google's most efficient model built for on-device tasks. It runs directly on user devices, leveraging hardware acceleration for fast and offline-capable AI features.",
      "paragraph2": "This version of Gemini Nano is integrated into Chrome and can be accessed via the `window.ai` API, allowing web developers to bring generative AI capabilities to their web applications."
    },
    "section3": {
      "title": "Key Features",
      "listItem1": "On-Device Processing: Ensures user privacy and enables offline functionality by running directly in the browser.",
      "listItem2": "Text Generation: Capable of generating coherent and contextually relevant text based on prompts.",
      "listItem3": "Efficiency: Optimized for resource-constrained environments, providing a balance between performance and model size.",
      "listItem4": "Web Platform Integration: Accessible through the `window.ai` API in Chrome, making it easy for web developers to use."
    },
    "section4": {
      "title": "How to Use This Playground",
      "paragraph1": "This playground provides an interactive way to test Gemini Nano's capabilities:",
      "listItem1": "Control Panel: Adjust model parameters like Temperature and Top-K to see how they affect the output. Initialize or restart the model if needed.",
      "listItem2": "Prompt Interface: Type your questions or instructions into the text area and click 'Send'. You can also try the provided prompt suggestions.",
      "listItem3": "Output Display: View the model's generated response. Note that generation can be stopped using the 'Stop' button.",
      "paragraph2": "Experiment with different prompts and settings to understand the model's behavior."
    },
    "section5": {
      "title": "Important Considerations",
      "paragraph1": "While Gemini Nano is powerful, keep these points in mind:",
      "listItem1": "Experimental Technology: This is an experimental feature. The API and model capabilities may change.",
      "listItem2": "Browser Compatibility: Currently, it's primarily available in Chrome versions that support the built-in AI SDK (e.g., Chrome Canary/Dev with specific flags enabled).",
      "listItem3": "Performance: Performance can vary based on your device hardware. The initial model download may take some time.",
      "listItem4": "Responsible AI: Generated content should be reviewed. Be mindful of potential biases or inaccuracies."
    },
    "section6": {
      "title": "Checking API Availability",
      "paragraph1": "Before attempting to use Gemini Nano, it's crucial to check if the API is available in the user's browser. This can be done by checking for the `window.LanguageModel` object and then calling its `availability()` method.",
      "paragraph2": "The `availability()` method returns a string indicating the current status, such as `available`, `readilyAvailable`, or `unavailable`. `readilyAvailable` means the model is downloaded and ready to use immediately. `available` may mean the model needs to be downloaded first.",
      "codeBlock1_Description": "Example of checking API availability:",
      "codeBlock1": "async function checkApi() {\n  if (window.LanguageModel) {\n    try {\n      const availability = await window.LanguageModel.availability();\n      console.log('API Availability:', availability);\n      // Update UI based on availability:\n      // 'available' - Model exists but may need a download.\n      // 'readilyAvailable' - Model is downloaded and ready.\n      // 'unavailable' - No model available / API disabled / not supported.\n      return availability;\n    } catch (error) {\n      console.error('Error checking API availability:', error);\n      return 'unavailable';\n    }\n  } else {\n    console.log('window.LanguageModel API not found.');\n    return 'unavailable';\n  }\n}\ncheckApi();"
    },
    "section7": {
      "title": "Creating a Model Session & Parameters",
      "paragraph1": "Once you've confirmed the API is available, you can create a model session. A session represents an instance of the language model with specific configurations.",
      "subsection1_title": "Model Parameters",
      "subsection1_paragraph1": "When creating a session, you can specify parameters to control the model's behavior:",
      "subsection1_listItem1": "`temperature`: Controls randomness. Higher values (e.g., 0.8) make output more random, lower values (e.g., 0.2) make it more deterministic. Default is often around 0.7.",
      "subsection1_listItem2": "`topK`: Narrows the model's choices to the `K` most likely next tokens. A lower `topK` (e.g., 3) makes the output more focused and less diverse. Default might be higher (e.g., 40).",
      "subsection1_paragraph2": "These parameters are usually set during session creation but some APIs might allow adjusting them later.",
      "codeBlock1_Description": "Example of creating a model session with parameters:",
      "codeBlock1": "async function createSession() {\n  if (!window.LanguageModel || await window.LanguageModel.availability() === 'unavailable') {\n    console.log('LanguageModel API not available or model unavailable.');\n    return null;\n  }\n  try {\n    const session = await window.LanguageModel.create({\n      temperature: 0.7, // Example temperature\n      topK: 40,         // Example topK\n      // Add other parameters like systemInstruction if supported/needed\n    });\n    console.log('Session created:', session);\n    return session;\n  } catch (error) {\n    console.error('Error creating session:', error);\n    return null;\n  }\n}\n// const mySession = await createSession();"
    },
    "section8": {
      "title": "Sending Prompts",
      "paragraph1": "After creating a session, you can send prompts to the model to get responses. There are two main ways to receive responses: as a single complete response or by streaming chunks of the response as they are generated.",
      "subsection1_title": "Simple Prompts (Full Response)",
      "subsection1_paragraph1": "For shorter interactions where you want the entire response at once, use the `prompt()` method. This method returns a promise that resolves with the full text generated by the model.",
      "codeBlock1_Description": "Example of sending a simple prompt:",
      "codeBlock1": "async function sendSimplePrompt(session, text) {\n  if (!session) {\n    console.error('Session not available.');\n    return;\n  }\n  try {\n    console.log('Sending prompt:', text);\n    const result = await session.prompt(text);\n    console.log('Full response:', result);\n    // Update your UI with the result\n  } catch (error) {\n    console.error('Error sending prompt:', error);\n  }\n}\n// Assuming 'mySession' is an active session:\n// sendSimplePrompt(mySession, \"Explain quantum physics in simple terms.\");",
      "subsection2_title": "Streaming Prompts (Chunks)",
      "subsection2_paragraph1": "For longer responses or real-time feedback, streaming is preferred. The `promptStreaming()` method returns an asynchronous iterable stream. You can loop through this stream to get chunks of text as the model generates them.",
      "codeBlock2_Description": "Example of sending a streaming prompt:",
      "codeBlock2": "async function sendStreamingPrompt(session, text) {\n  if (!session) {\n    console.error('Session not available.');\n    return;\n  }\n  try {\n    console.log('Sending streaming prompt:', text);\n    const stream = session.promptStreaming(text);\n    let fullResponse = '';\n    for await (const chunk of stream) {\n      console.log('Stream chunk:', chunk);\n      fullResponse += chunk;\n      // Update your UI with the chunk or accumulating fullResponse\n    }\n    console.log('Complete streamed response:', fullResponse);\n  } catch (error) {\n    console.error('Error sending streaming prompt:', error);\n  }\n}\n// Assuming 'mySession' is an active session:\n// sendStreamingPrompt(mySession, \"Write a short story about a robot exploring a new planet.\");"
    },
    "section9": {
      "title": "Model Downloads",
      "paragraph1": "The Gemini Nano model might need to be downloaded to the user's device before it can be used. The API's `availability()` method can return `'available'`, indicating a download might be necessary, or `'readilyAvailable'` if it's already downloaded.",
      "paragraph2": "This playground automatically handles the download process when you click 'Initialize Model'. You'll see a progress indicator. If you are building your own application, you would typically initiate a session creation, and the browser would handle the download if needed, possibly providing progress through API events if the spec supports it (the exact mechanism can vary).",
      "paragraph3": "Ensure users are aware that a download might occur, especially on metered connections. Providing clear feedback during this process is essential for a good user experience."
    },
    "section10": {
      "title": "Error Handling",
      "paragraph1": "It's important to implement robust error handling when working with the Gemini Nano API. Operations like checking availability, creating a session, or sending prompts can fail for various reasons (e.g., API disabled, no network, internal errors).",
      "paragraph2": "Always use `try...catch` blocks around asynchronous API calls to gracefully handle potential errors and provide feedback to the user.",
      "codeBlock1_Description": "General approach to error handling (conceptual):",
      "codeBlock1": "async function performAiTask() {\n  try {\n    // Example: Check availability\n    if (!window.LanguageModel || await window.LanguageModel.availability() === 'unavailable') {\n      throw new Error('AI Model is not available.');\n    }\n\n    // Example: Create session\n    const session = await window.LanguageModel.create({ /* params */ });\n    if (!session) {\n      throw new Error('Failed to create AI session.');\n    }\n\n    // Example: Send prompt\n    const response = await session.prompt(\"Your prompt here\");\n    // Process response\n\n  } catch (error) {\n    console.error(\"An error occurred:\", error.message);\n    // Update UI to inform the user (e.g., display error.message)\n  }\n}\n// performAiTask();",
      "paragraph3": "Inspect the error object for details. The API might throw specific error types or provide error codes in the future, which can help in diagnosing issues."
    }
  },
  "tabs": {
    "chat": "Chat",
    "guide": "Developer Guide"
  }
}
